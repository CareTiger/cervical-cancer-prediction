{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cervical Cancer prediction\n",
    "\n",
    "#### Source - https://archive.ics.uci.edu/ml/datasets/Cervical+cancer+%28Risk+Factors%29#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV # Hyperparameter tuning\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import roc_curve, plot_confusion_matrix, classification_report, plot_roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.a Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    df = pd.read_csv(filepath, na_values='?')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'risk_factors_cervical_cancer.csv'\n",
    "pre_df = load_data(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.b Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(858, 36)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 858 entries, 0 to 857\n",
      "Data columns (total 36 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Age                                 858 non-null    int64  \n",
      " 1   Number of sexual partners           832 non-null    float64\n",
      " 2   First sexual intercourse            851 non-null    float64\n",
      " 3   Num of pregnancies                  802 non-null    float64\n",
      " 4   Smokes                              845 non-null    float64\n",
      " 5   Smokes (years)                      845 non-null    float64\n",
      " 6   Smokes (packs/year)                 845 non-null    float64\n",
      " 7   Hormonal Contraceptives             750 non-null    float64\n",
      " 8   Hormonal Contraceptives (years)     750 non-null    float64\n",
      " 9   IUD                                 741 non-null    float64\n",
      " 10  IUD (years)                         741 non-null    float64\n",
      " 11  STDs                                753 non-null    float64\n",
      " 12  STDs (number)                       753 non-null    float64\n",
      " 13  STDs:condylomatosis                 753 non-null    float64\n",
      " 14  STDs:cervical condylomatosis        753 non-null    float64\n",
      " 15  STDs:vaginal condylomatosis         753 non-null    float64\n",
      " 16  STDs:vulvo-perineal condylomatosis  753 non-null    float64\n",
      " 17  STDs:syphilis                       753 non-null    float64\n",
      " 18  STDs:pelvic inflammatory disease    753 non-null    float64\n",
      " 19  STDs:genital herpes                 753 non-null    float64\n",
      " 20  STDs:molluscum contagiosum          753 non-null    float64\n",
      " 21  STDs:AIDS                           753 non-null    float64\n",
      " 22  STDs:HIV                            753 non-null    float64\n",
      " 23  STDs:Hepatitis B                    753 non-null    float64\n",
      " 24  STDs:HPV                            753 non-null    float64\n",
      " 25  STDs: Number of diagnosis           858 non-null    int64  \n",
      " 26  STDs: Time since first diagnosis    71 non-null     float64\n",
      " 27  STDs: Time since last diagnosis     71 non-null     float64\n",
      " 28  Dx:Cancer                           858 non-null    int64  \n",
      " 29  Dx:CIN                              858 non-null    int64  \n",
      " 30  Dx:HPV                              858 non-null    int64  \n",
      " 31  Dx                                  858 non-null    int64  \n",
      " 32  Hinselmann                          858 non-null    int64  \n",
      " 33  Schiller                            858 non-null    int64  \n",
      " 34  Citology                            858 non-null    int64  \n",
      " 35  Biopsy                              858 non-null    int64  \n",
      "dtypes: float64(26), int64(10)\n",
      "memory usage: 241.4 KB\n"
     ]
    }
   ],
   "source": [
    "pre_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total missing values  3622\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-718ad23da3bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Total missing values \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Percent values missing \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# count missing values\n",
    "\n",
    "print(\"Total missing values \", pre_df.isnull().sum().sum())\n",
    "print(\"Percent values missing \", round(pre_df.isnull().sum().sum()/pre_df.size*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify columns with more than 60% null values\n",
    "pre_df.dropna(thresh=len(pre_df)*0.6,how='all',axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df['Biopsy'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1c. Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(df):\n",
    "\n",
    "    # drop some cols to prevent leakage because the columns are POSSIBLY \n",
    "    # additional target variables\n",
    "    drop_cols = ['Hinselmann', 'Schiller', 'Citology']\n",
    "    df.drop(columns=drop_cols, inplace=True)\n",
    "    \n",
    "    #fill nan \n",
    "    df = df.fillna(df.mean().to_dict())\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wrangle(pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Biopsy'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-55/858"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=df[\"Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x=\"Age\", y=\"STDs\", hue=\"Biopsy\", data=df)\n",
    "# Chart shows that STD alone doesnt explain malignancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    df,\n",
    "    x_vars=[\"Age\", \"Num of pregnancies\", \"Smokes (years)\", \"Biopsy\"],\n",
    "    y_vars=[\"Age\", \"Num of pregnancies\", \"Smokes (years)\", \"Biopsy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Biopsy'\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into Test/Train/Validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.2, random_state=30)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, shuffle=True, test_size=0.3, random_state=30)\n",
    "\n",
    "# with SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "cc = SMOTETomek(random_state=2019)\n",
    "X_train, y_train = cc.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Establish the Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_acc = y_train.value_counts(normalize=True).max()\n",
    "print('Baseline Accuracy:', baseline_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "model_lg = make_pipeline(\n",
    "            SimpleImputer(strategy='mean'),\n",
    "            LogisticRegression(class_weight=\"balanced\")\n",
    "            )\n",
    "\n",
    "model_lg.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = make_pipeline(OrdinalEncoder(),\n",
    "                         XGBClassifier(scale_pos_weight = 803/55,\n",
    "                                         n_estimators=100,\n",
    "                                          max_depth=10,\n",
    "                                          learning_rate=1e-3,\n",
    "                                          n_jobs=10))\n",
    "\n",
    "model_xgb.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest\n",
    "model_rf = make_pipeline(\n",
    "        OrdinalEncoder(),\n",
    "        SimpleImputer(),\n",
    "        RandomForestClassifier(n_estimators=25,\n",
    "                               n_jobs=-1,\n",
    "                               random_state=42)\n",
    "        )\n",
    "\n",
    "model_rf.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "lg_train_acc = model_lg.score(X_train, y_train)\n",
    "lg_val_acc = model_lg.score(X_val, y_val)\n",
    "print('Logistic regression Training Accuracy Score:', lg_train_acc)\n",
    "print('Logistic regression Validation Accuracy Score:', lg_val_acc)\n",
    "\n",
    "# XG BOOST\n",
    "xgb_train_acc = model_xgb.score(X_train, y_train)\n",
    "xgb_val_acc = model_xgb.score(X_val, y_val)\n",
    "print('XGB Training Accuracy Score:', xgb_train_acc)\n",
    "print('XGB Validation Accuracy Score:', xgb_val_acc)\n",
    "\n",
    "# RANDOM FOREST\n",
    "rf_train_acc = model_rf.score(X_train, y_train)\n",
    "rf_val_acc = model_rf.score(X_val, y_val)\n",
    "print('Random Forest Training Accuracy Score:', rf_train_acc)\n",
    "print('Random Forest Validation Accuracy Score:', rf_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Select and tune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Validation Accuracy scores above suggest \n",
    "# that We select the Random forest model as our preferred model\n",
    "# So I plot the ROC curve to get further insights into this choice\n",
    "\n",
    "lr = plot_roc_curve(model_lg, X_test, y_test, label='Logistic')\n",
    "xg = plot_roc_curve(model_xgb, X_test, y_test, ax=lr.ax_, label='XG Boost')\n",
    "rf = plot_roc_curve(model_rf, X_test, y_test, ax=lr.ax_, label='RandomForest')\n",
    "plt.plot([(0,0), (1,1)], color='grey', linestyle='--')\n",
    "plt.legend();\n",
    "\n",
    "# The plot suggests that Random Forest is a good choice for predicting Malignant cancer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_roc_auc_score = roc_auc_score(y_val, model_lg.predict(X_val))\n",
    "print(\"Logistic regression ROC-AUC score\", lg_roc_auc_score)\n",
    "xg_roc_auc_score = roc_auc_score(y_val, model_xgb.predict(X_val))\n",
    "print(\"XG Boost ROC-AUC score\", xg_roc_auc_score)\n",
    "rf_roc_auc_score = roc_auc_score(y_val, model_rf.predict(X_val))\n",
    "print(\"Random Forest ROC-AUC score\", rf_roc_auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg_recall_score = recall_score(y_val, model_lg.predict(X_val))\n",
    "print(\"Logistic regression recall score\", lg_roc_auc_score)\n",
    "xg_recall_score = recall_score(y_val, model_xgb.predict(X_val))\n",
    "print(\"XG Boost recall score\", xg_roc_auc_score)\n",
    "rf_recall_score = recall_score(y_val, model_rf.predict(X_val))\n",
    "print(\"Random Forest recall score\", rf_roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'simpleimputer__strategy': ['mean', 'median'],\n",
    "#     'randomforestclassifier__max_depth': range(5,40,5),\n",
    "#     'randomforestclassifier__n_estimators': range(25, 125, 25)\n",
    "# }\n",
    "\n",
    "# model_rs = RandomizedSearchCV(\n",
    "#     model_rf, \n",
    "#     param_distributions=param_grid,\n",
    "#     n_iter=3,\n",
    "#     cv=None,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# model_rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model_lg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Communicate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix using LogisticRegression\n",
    "disp = plot_confusion_matrix(\n",
    "    model_lg,\n",
    "    X_val, # USE VALIDATION DATA\n",
    "    y_val,\n",
    "    values_format='.0f',\n",
    "    display_labels=['no cancer', 'has cancer']\n",
    ");\n",
    "disp.ax_.set_title(\"Logistic Regression\")\n",
    "print(disp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix using XG Boost\n",
    "disp = plot_confusion_matrix(\n",
    "    model_xgb,\n",
    "    X_val, # USE VALIDATION DATA\n",
    "    y_val,\n",
    "    values_format='.0f',\n",
    "    display_labels=['no cancer', 'has cancer']\n",
    ");\n",
    "disp.ax_.set_title(\"XG Boost\")\n",
    "print(disp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix using Random Forest\n",
    "disp = plot_confusion_matrix(\n",
    "    model_rf,\n",
    "    X_val, # USE VALIDATION DATA\n",
    "    y_val,\n",
    "    values_format='.0f',\n",
    "    display_labels=['no cancer', 'has cancer']\n",
    ");\n",
    "disp.ax_.set_title(\"Random Forest\")\n",
    "print(disp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(model_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importances = model_lg.named_steps['logisticregression'].feature_importances_\n",
    "# features = model_lg.named_steps['ordinalencoder'].get_feature_names()\n",
    "# feat_imp = pd.Series(importances, index=features).sort_values()\n",
    "# feat_imp.tail(20).plot(kind='barh')\n",
    "# plt.xlabel('Reduction in Gini Impurity');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation importance Logistic REgression\n",
    "per_imp = permutation_importance(model_lg, \n",
    "                                 X_val, \n",
    "                                 y_val,\n",
    "                                 n_repeats=5, \n",
    "                                 n_jobs=-1, \n",
    "                                 random_state=42 )\n",
    "pd.Series(per_imp['importances_mean'], index=X_val.columns).sort_values().tail(10).plot(kind='barh')\n",
    "plt.xlabel('premutation importance')\n",
    "plt.ylabel('feature name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation importance XG Boost\n",
    "per_imp = permutation_importance(model_xgb, \n",
    "                                 X_val, \n",
    "                                 y_val,\n",
    "                                 n_repeats=5, \n",
    "                                 n_jobs=-1, \n",
    "                                 random_state=42 )\n",
    "pd.Series(per_imp['importances_mean'], index=X_val.columns).sort_values().tail(10).plot(kind='barh')\n",
    "plt.xlabel('premutation importance')\n",
    "plt.ylabel('feature name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# permutation importance Random Fores\n",
    "per_imp = permutation_importance(model_rf, \n",
    "                                 X_val, \n",
    "                                 y_val,\n",
    "                                 n_repeats=5, \n",
    "                                 n_jobs=-1, \n",
    "                                 random_state=42 )\n",
    "pd.Series(per_imp['importances_mean'], index=X_val.columns).sort_values().tail(10).plot(kind='barh')\n",
    "plt.xlabel('premutation importance')\n",
    "plt.ylabel('feature name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pdpbox.pdp import pdp_isolate, pdp_plot\n",
    "# feature = 'Age'\n",
    "\n",
    "# isolated = pdp_isolate(model=model_rf,\n",
    "#            dataset=X_val, \n",
    "#            model_features=X_val.columns,\n",
    "#            feature= feature)\n",
    "\n",
    "# pdp_plot(isolated,feature_name=feature,plot_lines=True, frac_to_plot=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
